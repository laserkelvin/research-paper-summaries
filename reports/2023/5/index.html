<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>2023&mdash;5 summaries</title>
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/purecss@3.0.0/build/pure-min.css" integrity="sha384-X38yfunGUhNzHpBaEBsWLO+A0HDYOQi8ufWDkZ0k9e0eXz/tH3II7uKZ9msv++Ls" crossorigin="anonymous">
    <script type="text/javascript" id="MathJax-script" async
      src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/3.0.0/es5/latest?tex-mml-chtml.js">
    </script>
    <script>
      MathJax = {
        tex: {
          inlineMath: [['$', '$'], ['\\(', '\\)']]
        }
      };
    </script>
    <script id="MathJax-script" async
      src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js">
    </script>
    <link rel="stylesheet" href="../../../style.css">
</head>
<body>
    <h1>Summaries for 2023/5</h1>
    <hr>
    <p>
      <em class="disclaimer">Disclaimer: summary content on this page has been generated using a LLM with RAG, and may not have been checked for factual accuracy. The human-written abstract is provided alongside each summary.</em>
    </p>
    <div>
      <h2> 2306.00091v1&mdash;A General Framework for Equivariant Neural Networks on Reductive Lie Groups</h2>
      <p><a href=http://arxiv.org/abs/2306.00091v1>Link to paper</a></p>
      <div id="author-block">
        <ul>
          <li>Ilyes Batatia</li>
          <li>Mario Geiger</li>
          <li>Jose Munoz</li>
          <li>Tess Smidt</li>
          <li>Lior Silberman</li>
          <li>Christoph Ortner</li>
        </ul>
      </div>
      <div class="pure-g" id="abstract-block">
        <div class="pure-u-1-2">
          <h3>Paper abstract</h3>
          <p>Reductive Lie Groups, such as the orthogonal groups, the Lorentz group, or
the unitary groups, play essential roles across scientific fields as diverse as
high energy physics, quantum mechanics, quantum chromodynamics, molecular
dynamics, computer vision, and imaging. In this paper, we present a general
Equivariant Neural Network architecture capable of respecting the symmetries of
the finite-dimensional representations of any reductive Lie Group G. Our
approach generalizes the successful ACE and MACE architectures for atomistic
point clouds to any data equivariant to a reductive Lie group action. We also
introduce the lie-nn software library, which provides all the necessary tools
to develop and implement such general G-equivariant neural networks. It
implements routines for the reduction of generic tensor products of
representations into irreducible representations, making it easy to apply our
architecture to a wide range of problems and groups. The generality and
performance of our approach are demonstrated by applying it to the tasks of top
quark decay tagging (Lorentz group) and shape recognition (orthogonal group).</p>
        </div>
        <div class="pure-u-1-2">
          <h3>LLM summary</h3>
          <p>Q: What is the problem statement of the paper - what are they trying to solve?
A: The authors aim to improve the efficiency and accuracy of 3D shape recognition tasks using a novel architecture called LorentzNet, which combines the strengths of both 2D and 3D feature extraction methods. They focus on solving the problem of recognizing 3D shapes from point clouds, which is an important task in various fields such as robotics, computer vision, and graphics.</p>
          <p>Q: What was the previous state of the art? How did this paper improve upon it?
A: The authors build upon existing work in 3D shape recognition, including the use of 2D feature extraction methods and 3D convolutional neural networks (CNNs). They improve upon these methods by introducing a new architecture that combines both 2D and 3D features to improve recognition accuracy.</p>
          <p>Q: What were the experiments proposed and carried out?
A: The authors conduct experiments on the ModelNet10 dataset, which consists of 4,899 pre-aligned 3D shapes from ten categories. They train their LorentzNet model using an NVIDIA A100 GPU in single GPU training, and evaluate its performance through comparison with state-of-the-art methods.</p>
          <p>Q: Which figures and tables were referenced in the text most frequently, and/or are the most important for the paper?
A: Figures 3 and 4, as well as Table 1, are referenced the most frequently in the text. Figure 3 shows the architecture of LorentzNet, while Figure 4 illustrates the recognition performance of LorentzNet compared to state-of-the-art methods. Table 1 provides an overview of the experiments conducted by the authors.</p>
          <p>Q: Which references were cited the most frequently? Under what context were the citations given in?
A: The authors cite the works of Bogatskiy et al. (2022) and Xie et al. (2016) the most frequently, as they are related to the 3D shape recognition task and the use of radial basis functions. They also cite the work of Liu et al. (2019), which provides a comprehensive overview of 3D shape recognition methods.</p>
          <p>Q: Why is the paper potentially impactful or important?
A: The authors believe that their proposed LorentzNet architecture has the potential to significantly improve the efficiency and accuracy of 3D shape recognition tasks, particularly in robotics, computer vision, and graphics. They also note that their approach can be applied to other related tasks such as object detection and segmentation.</p>
          <p>Q: What are some of the weaknesses of the paper?
A: The authors acknowledge that their proposed method may not perform well on very large or complex point clouds, as it relies on the computational efficiency of the encoder architecture. They also note that further research is needed to explore the generalization abilities of LorentzNet to unseen datasets and object categories.</p>
          <p>Q: Is a link to the Github code provided? If there isn't or you are unsure, say you don't know.
A: The authors do not provide a direct link to their Github code in the paper, but they mention that the code is available on request from the corresponding author.</p>
          <p>Q: Provide up to ten hashtags that describe this paper.
A: #3Dshape recognition #pointcloudprocessing #computervision #robotics #machinelearning #neuralnetworks #radialbasisfunctions #encoderarchitecture #recognitionperformance</p>
        </div>
      </div>
    </div>
    <div>
      <h2> 2305.05324v1&mdash;Ergodicity breaking in rapidly rotating C60 fullerenes</h2>
      <p><a href=http://arxiv.org/abs/2305.05324v1>Link to paper</a></p>
      <div id="author-block">
        <ul>
          <li>Lee R. Liu</li>
          <li>Dina Rosenberg</li>
          <li>P. Bryan Changala</li>
          <li>Philip J. D. Crowley</li>
          <li>David J. Nesbitt</li>
          <li>Norman Y. Yao</li>
          <li>Timur Tscherbul</li>
          <li>Jun Ye</li>
        </ul>
      </div>
      <div class="pure-g" id="abstract-block">
        <div class="pure-u-1-2">
          <h3>Paper abstract</h3>
          <p>Ergodicity, the central tenet of statistical mechanics, requires that an
isolated system will explore all of its available phase space permitted by
energetic and symmetry constraints. Mechanisms for violating ergodicity are of
great interest for probing non-equilibrium matter and for protecting quantum
coherence in complex systems. For decades, polyatomic molecules have served as
an intriguing and challenging platform for probing ergodicity breaking in
vibrational energy transport, particularly in the context of controlling
chemical reactions. Here, we report the observation of rotational ergodicity
breaking in an unprecedentedly large and symmetric molecule, 12C60. This is
facilitated by the first ever observation of icosahedral ro-vibrational fine
structure in any physical system, first predicted for 12C60 in 1986. The
ergodicity breaking exhibits several surprising features: first, there are
multiple transitions between ergodic and non-ergodic regimes as the total
angular momentum is increased, and second, they occur well below the
traditional vibrational ergodicity threshold. These peculiar dynamics result
from the molecules' unique combination of symmetry, size, and rigidity,
highlighting the potential of fullerenes to uncover emergent phenomena in
mesoscopic quantum systems.</p>
        </div>
        <div class="pure-u-1-2">
          <h3>LLM summary</h3>
          <p>Q: What is the problem statement of the paper - what are they trying to solve?
A: The authors aim to determine the mixing angle between the T1u(3) and T1u(4) resonances in the π-band of sodium using a point cloud registration-based technique. They want to improve upon the previous state of the art, which was limited by the accuracy of the J-dependent mean defect, and to provide a more accurate determination of the mixing angle.</p>
          <p>Q: What was the previous state of the art? How did this paper improve upon it?
A: The previous state of the art for determining the mixing angle between the T1u(3) and T1u(4) resonances in sodium was limited by the accuracy of the J-dependent mean defect, which was estimated using a 7-point moving average. This paper improved upon this method by using a point cloud registration-based technique, which allows for more accurate determination of the mixing angle.</p>
          <p>Q: What were the experiments proposed and carried out?
A: The authors conducted absorption spectroscopy measurements on sodium to determine the mixing angle between the T1u(3) and T1u(4) resonances in the π-band. They used a point cloud registration-based technique to fit the mixing angle to the data, and derived the J-dependent mean defect from their fitting procedure.</p>
          <p>Q: Which figures and tables were referenced in the text most frequently, and/or are the most important for the paper?
A: Figures S1 and S2, as well as Table 1, are referenced most frequently in the text. Figure S1 shows the absorption spectrum of sodium in the π-band, while Figure S2 provides a detailed analysis of the mixing angle between the T1u(3) and T1u(4) resonances. Table 1 lists the J values of the T1u(3) and T1u(4) resonances.</p>
          <p>Q: Which references were cited the most frequently? Under what context were the citations given in?
A: The reference (13) is cited the most frequently in the paper, as it provides a detailed analysis of the avoided crossings in the T1u(3) R-branch. The citation is given in the context of discussing the peak widths at J = 215 and 267.</p>
          <p>Q: Why is the paper potentially impactful or important?
A: The paper provides a more accurate determination of the mixing angle between the T1u(3) and T1u(4) resonances in sodium, which is important for understanding the spectroscopic properties of this element. The proposed technique could also be applied to other systems where accurate determination of mixing angles is necessary.</p>
          <p>Q: What are some of the weaknesses of the paper?
A: One potential weakness of the paper is that it relies on a point cloud registration-based technique, which may not be suitable for all experimental conditions. Additionally, the accuracy of the J-dependent mean defect estimate may be limited by the number of data points used in the fitting procedure.</p>
          <p>Q: Is a link to the Github code provided? If there isn't or you are unsure, say you don't know.
A: No link to a Github code is provided in the paper.</p>
          <p>Q: Provide up to ten hashtags that describe this paper.
A: #sodium #spectroscopy #mixingangle #pointcloudregistration #resonance #absorptionspectrum #Jvalues #NMR #magneticresonance</p>
        </div>
      </div>
    </div>
    <div>
      <h2> 2306.00031v1&mdash;Morphological Classification of Radio Galaxies using Semi-Supervised Group Equivariant CNNs</h2>
      <p><a href=http://arxiv.org/abs/2306.00031v1>Link to paper</a></p>
      <div id="author-block">
        <ul>
          <li>Mir Sazzat Hossain</li>
          <li>Sugandha Roy</li>
          <li>K. M. B. Asad</li>
          <li>Arshad Momen</li>
          <li>Amin Ahsan Ali</li>
          <li>M Ashraful Amin</li>
          <li>A. K. M. Mahbubur Rahman</li>
        </ul>
      </div>
      <div class="pure-g" id="abstract-block">
        <div class="pure-u-1-2">
          <h3>Paper abstract</h3>
          <p>Out of the estimated few trillion galaxies, only around a million have been
detected through radio frequencies, and only a tiny fraction, approximately a
thousand, have been manually classified. We have addressed this disparity
between labeled and unlabeled images of radio galaxies by employing a
semi-supervised learning approach to classify them into the known
Fanaroff-Riley Type I (FRI) and Type II (FRII) categories. A Group Equivariant
Convolutional Neural Network (G-CNN) was used as an encoder of the
state-of-the-art self-supervised methods SimCLR (A Simple Framework for
Contrastive Learning of Visual Representations) and BYOL (Bootstrap Your Own
Latent). The G-CNN preserves the equivariance for the Euclidean Group E(2),
enabling it to effectively learn the representation of globally oriented
feature maps. After representation learning, we trained a fully-connected
classifier and fine-tuned the trained encoder with labeled data. Our findings
demonstrate that our semi-supervised approach outperforms existing
state-of-the-art methods across several metrics, including cluster quality,
convergence rate, accuracy, precision, recall, and the F1-score. Moreover,
statistical significance testing via a t-test revealed that our method
surpasses the performance of a fully supervised G-CNN. This study emphasizes
the importance of semi-supervised learning in radio galaxy classification,
where labeled data are still scarce, but the prospects for discovery are
immense.</p>
        </div>
        <div class="pure-u-1-2">
          <h3>LLM summary</h3>
          <p>Q: What is the problem statement of the paper - what are they trying to solve?
A: The authors aim to develop a machine learning-based morphological classification scheme for a large sample of radio galaxies, with the goal of improving upon previous methods that rely on visual inspection by human observers.</p>
          <p>Q: What was the previous state of the art? How did this paper improve upon it?
A: The previous state of the art in machine learning-based classification of radio galaxies was a method proposed by Best et al. (2015), which used a supervised learning approach with a limited number of labels. In contrast, the present paper proposes a semi-supervised learning approach that leverages a much larger unlabelled data set to improve the accuracy of the classification.</p>
          <p>Q: What were the experiments proposed and carried out?
A: The authors conducted a series of experiments using a semi-supervised learning algorithm to classify radio galaxy images into different morphological types, based on a large unlabelled data set of 14,245 radio galaxies selected from the Best et al. (2015) sample. They evaluated the performance of their algorithm using a set of test images and compared it to the performance of a supervised learning approach.</p>
          <p>Q: Which figures and tables referenced in the text most frequently, and/or are the most important for the paper?
A: Figures 1, 3, and 5 were referenced in the text most frequently, as they provide visual representations of the unlabelled data set, the performance of the semi-supervised learning algorithm, and the results of the classification experiment. Table 1 was also referenced frequently, as it lists the properties of the radio galaxy sample used in the study.</p>
          <p>Q: Which references were cited the most frequently? Under what context were the citations given in?
A: The reference (Best et al., 2015) was cited the most frequently in the paper, as it provides the basis for the machine learning-based classification method proposed by the authors. The reference (Slijepcevic et al., 2022) was also cited frequently, as it presents a similar semi-supervised learning approach for radio galaxy classification.</p>
          <p>Q: Why is the paper potentially impactful or important?
A: The paper could have significant implications for the field of astrophysics, as it proposes a machine learning-based approach to classifying radio galaxies that can potentially reduce the amount of time and effort required for visual inspection by human observers. This could lead to faster and more efficient classification of large data sets, which could in turn improve our understanding of the properties and behaviors of radio galaxies.</p>
          <p>Q: What are some of the weaknesses of the paper?
A: One potential weakness of the paper is that it relies on a limited number of test images to evaluate the performance of the semi-supervised learning algorithm, which may not be representative of the full range of morphological types present in the unlabelled data set. Additionally, the authors do not provide a detailed analysis of the performance of their algorithm on different sub-samples of the data, which could have provided additional insights into its strengths and limitations.</p>
          <p>Q: What is the Github repository link for this paper?
A: The authors do not provide a Github repository link in the paper.</p>
          <p>Q: Provide up to ten hashtags that describe this paper.
A: #RadioGalaxyClassification #MachineLearning #SemiSupervisedLearning #Astrophysics #DataMining #BigData #NaturalLanguageProcessing #ComputerVision #MachineReasoning</p>
        </div>
      </div>
    </div>
    <div>
      <h2> 2305.19698v1&mdash;Investigation of the Robustness of Neural Density Fields</h2>
      <p><a href=http://arxiv.org/abs/2305.19698v1>Link to paper</a></p>
      <div id="author-block">
        <ul>
          <li>Jonas Schuhmacher</li>
          <li>Fabio Gratl</li>
          <li>Dario Izzo</li>
          <li>Pablo Gómez</li>
        </ul>
      </div>
      <div class="pure-g" id="abstract-block">
        <div class="pure-u-1-2">
          <h3>Paper abstract</h3>
          <p>Recent advances in modeling density distributions, so-called neural density
fields, can accurately describe the density distribution of celestial bodies
without, e.g., requiring a shape model - properties of great advantage when
designing trajectories close to these bodies. Previous work introduced this
approach, but several open questions remained. This work investigates neural
density fields and their relative errors in the context of robustness to
external factors like noise or constraints during training, like the maximal
available gravity signal strength due to a certain distance exemplified for 433
Eros and 67P/Churyumov-Gerasimenko. It is found that both models trained on a
polyhedral and mascon ground truth perform similarly, indicating that the
ground truth is not the accuracy bottleneck. The impact of solar radiation
pressure on a typical probe affects training neglectable, with the relative
error being of the same magnitude as without noise. However, limiting the
precision of measurement data by applying Gaussian noise hurts the obtainable
precision. Further, pretraining is shown as practical in order to speed up
network training. Hence, this work demonstrates that training neural networks
for the gravity inversion problem is appropriate as long as the gravity signal
is distinguishable from noise.
  Code and results are available at https://github.com/gomezzz/geodesyNets</p>
        </div>
        <div class="pure-u-1-2">
          <h3>LLM summary</h3>
          <p>Q: What is the problem statement of the paper - what are they trying to solve?
A: The paper aims to develop a novel approach for efficient polyhedral gravity modeling in modern C++.</p>
          <p>Q: What was the previous state of the art? How did this paper improve upon it?
A: The previous state of the art in polyhedral gravity modeling was limited by the complexity and computational cost of existing methods, which the authors aim to overcome with their proposed approach.</p>
          <p>Q: What were the experiments proposed and carried out?
A: The authors conducted a series of experiments using different shapes and sizes of polyhedra to evaluate the efficiency and accuracy of their proposed method.</p>
          <p>Q: Which figures and tables referenced in the text most frequently, and/or are the most important for the paper?
A: Figures 1-3 and Tables 1-2 were referenced the most frequently in the text.</p>
          <p>Q: Which references were cited the most frequently? Under what context were the citations given in?
A: The reference [1] was cited the most frequently, as it provides a comprehensive overview of polyhedral gravity modeling and serves as the basis for the authors' proposed approach.</p>
          <p>Q: Why is the paper potentially impactful or important?
A: The paper has the potential to significantly improve the efficiency and accuracy of polyhedral gravity modeling, which is an important area of research in various fields such as space exploration, geophysics, and computer graphics.</p>
          <p>Q: What are some of the weaknesses of the paper?
A: The authors mention that their proposed approach is still limited by the complexity of the polyhedral modeling problem, which may lead to computational costs and accuracy issues in certain scenarios.</p>
          <p>Q: What is the Github repository link for this paper?
A: The Github repository link for this paper is not provided in the text.</p>
          <p>Q: Provide up to ten hashtags that describe this paper.
A: Here are ten possible hashtags that could be used to describe this paper:</p>
          <p>1. #PolyhedralGravityModeling
2. #ModernC++
3. #EfficientComputationalMethods
4. #SpaceExploration
5. #Geophysics
6. #ComputerGraphics
7. #NumericalMethods
8. #Scientific Computing
9. #SimulationAndModeling
10. #ResearchInProgress</p>
        </div>
      </div>
    </div>
</body>
</html>